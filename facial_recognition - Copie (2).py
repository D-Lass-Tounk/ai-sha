import cv2
import time
import os
import threading
import numpy as np
from PIL import Image
from datetime import datetime
import tkinter as tk
from tkinter import simpledialog
from insightface.app import FaceAnalysis
from numpy import dot
from numpy.linalg import norm
import mediapipe as mp
import smtplib
from email.message import EmailMessage

# === Couleur des points (visage + main) ===
POINT_COLOR = (200, 255, 255)  # Bleu clair

# Fonction pour envoyer un e-mail
def send_email(subject, body, sender, receiver, password):
    msg = EmailMessage()
    msg.set_content(body)
    msg["Subject"] = subject
    msg["From"] = sender
    msg["To"] = receiver
    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465) as smtp:
            smtp.login(sender, password)
            smtp.send_message(msg)
        print("ðŸ“§ E-mail envoyÃ© avec succÃ¨s.")
    except Exception as e:
        print(f"âŒ Erreur lors de l'envoi de l'e-mail : {e}")

# Bip multiplateforme
try:
    import winsound
    def play_beep():
        for _ in range(3):
            winsound.Beep(800, 120)
        time.sleep(0.3)
except ImportError:
    import simpleaudio as sa
    def play_beep():
        wave_obj = sa.WaveObject.from_wave_file("beep.wav")
        for _ in range(3):
            wave_obj.play()
            time.sleep(0.12)
        time.sleep(0.3)

# Variables globales
model = None
known_encodings = []
known_names = []
last_face_bbox = None
last_frame = None
frame_lock = threading.Lock()
annotated_frame = None
unknown_face_counts = {}
MAX_UNKNOWN_SAVES = 3
email_sent = False  # pour Ã©viter dâ€™envoyer plusieurs fois

# Cosine similarity
def cosine_similarity(a, b):
    return dot(a, b) / (norm(a) * norm(b))

# Charger les visages
def load_known_faces(folder="faces"):
    encodings, names = [], []
    print(f"\nðŸ”„ Chargement des visages depuis : {folder}\n")
    os.makedirs(folder, exist_ok=True)
    for filename in os.listdir(folder):
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            path = os.path.join(folder, filename)
            print(f"ðŸ”Ž Analyse du fichier : {filename}")
            try:
                img = np.array(Image.open(path).convert("RGB"))
                faces = model.get(img)
                if faces:
                    encodings.append(faces[0].embedding)
                    name = filename.split("_")[0]
                    names.append(name)
                    print(f"âœ… Visage chargÃ© : {name}")
                else:
                    print(f"âŒ Aucun visage dÃ©tectÃ© dans : {filename}")
            except Exception as e:
                print(f"âš ï¸ Erreur sur {filename} : {e}")
    return encodings, names

# Enregistrement manuel
def save_face():
    global last_face_bbox, last_frame, known_encodings, known_names
    if last_face_bbox is None or last_frame is None:
        print("â›” Aucun visage Ã  sauvegarder.")
        return
    y1, x2, y2, x1 = last_face_bbox
    top = max(0, y1 - 20)
    bottom = min(last_frame.shape[0], y2 + 20)
    left = max(0, x1 - 20)
    right = min(last_frame.shape[1], x2 + 20)
    face_img = last_frame[top:bottom, left:right]

    root = tk.Tk()
    root.withdraw()
    name = simpledialog.askstring("Nom", "Entrez le nom du visage :")
    root.destroy()

    if not name:
        print("â›” Aucun nom entrÃ©.")
        return

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{name}_{timestamp}.jpg"
    path = os.path.join("faces", filename)
    cv2.imwrite(path, cv2.cvtColor(face_img, cv2.COLOR_RGB2BGR))
    print(f"ðŸ“‚ Visage sauvegardÃ© : {path}")

    faces = model.get(face_img)
    if faces:
        known_encodings.append(faces[0].embedding)
        known_names.append(name)
        print(f"ðŸ†• {name} ajoutÃ© Ã  la base.")
    else:
        print("âš ï¸ Ã‰chec de l'encodage â†’ veuillez rÃ©essayer.")

# Thread de dÃ©tection (visage + main)
def detection_thread_func():
    global annotated_frame, last_frame, last_face_bbox, email_sent
    mp_hands = mp.solutions.hands.Hands(static_image_mode=False, max_num_hands=2)
    while True:
        with frame_lock:
            if last_frame is None:
                continue
            frame_rgb = last_frame.copy()
        result_frame = frame_rgb.copy()
        faces = model.get(frame_rgb)

        for face in faces:
            x1, y1, x2, y2 = face.bbox.astype(int)
            emb = face.embedding
            label = "Visage inconnu"
            similarity = 0

            if known_encodings:
                scores = [cosine_similarity(emb, ref) for ref in known_encodings]
                max_score = max(scores)
                best_match = np.argmax(scores)
                if max_score > 0.38:
                    label = known_names[best_match]
                    similarity = max_score

            # Points du visage
            if hasattr(face, "landmark_3d_68") and face.landmark_3d_68 is not None:
                for (x, y, _) in face.landmark_3d_68.astype(int):
                    cv2.circle(result_frame, (x, y), 1, POINT_COLOR, -1)

            # Texte
            text = f"{label} ({int(similarity * 100)}%)" if similarity else label
            cv2.putText(result_frame, text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (64, 64, 64), 1)

            if label == "Visage inconnu":
                play_beep()
                last_face_bbox = (y1, x2, y2, x1)
                emb_key = tuple(np.round(emb[:10], 3))
                if unknown_face_counts.get(emb_key, 0) < MAX_UNKNOWN_SAVES:
                    os.makedirs("unknown", exist_ok=True)
                    filename = f"unknown_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
                    face_img = frame_rgb[y1:y2, x1:x2]
                    cv2.imwrite(os.path.join("unknown", filename), cv2.cvtColor(face_img, cv2.COLOR_RGB2BGR))
                    unknown_face_counts[emb_key] = unknown_face_counts.get(emb_key, 0) + 1
                    print(f"ðŸ“¸ Visage inconnu sauvegardÃ© ({unknown_face_counts[emb_key]}x)")

        # DÃ©tection des mains
        results = mp_hands.process(frame_rgb)
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                points = [(int(lm.x * frame_rgb.shape[1]), int(lm.y * frame_rgb.shape[0]))
                          for lm in hand_landmarks.landmark]
                for x, y in points:
                    cv2.circle(result_frame, (x, y), 2, POINT_COLOR, -1)

                # Relier les points
                for connection in mp.solutions.hands.HAND_CONNECTIONS:
                    start, end = connection
                    x1, y1 = points[start]
                    x2, y2 = points[end]
                    cv2.line(result_frame, (x1, y1), (x2, y2), (200, 200, 200), 1)

                # Compter les doigts levÃ©s
                finger_ids = [4, 8, 12, 16, 20]
                fingers_up = sum([1 for fid in finger_ids if points[fid][1] < points[fid - 2][1]])
                cx, cy = points[0]
                cv2.putText(result_frame, str(fingers_up), (cx, cy - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, POINT_COLOR, 2)

                # Envoi e-mail si deux doigts levÃ©s
                if fingers_up == 2 and not email_sent:
                    send_email(
                        subject="ðŸš¨ ALERTE - SIGNALE DE DANGER DÃ‰TECTÃ‰.",
                        body="Un signal de danger a Ã©tÃ© repÃ©rÃ© : un geste Ã  deux doigts a Ã©tÃ© dÃ©tectÃ© devant la camÃ©ra.",
                        sender="lasstounk2017@gmail.com",
                        receiver="lasstounk2023@gmail.com",
                        password="pczxinliuvioazxj"
                    )
                    email_sent = True  # Ã‰vite de le renvoyer plusieurs fois

        with frame_lock:
            annotated_frame = cv2.cvtColor(result_frame, cv2.COLOR_RGB2BGR)

# Main
def main():
    global model, known_encodings, known_names, last_frame
    model = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])
    model.prepare(ctx_id=0)
    known_encodings[:], known_names[:] = load_known_faces()

    cam = cv2.VideoCapture(0)
    cam.set(cv2.CAP_PROP_FPS, 30)
    if not cam.isOpened():
        print("âŒ Impossible d'ouvrir la webcam.")
        return

    print("\nðŸ“· CamÃ©ra ouverte. Appuyez sur :")
    print(" - 's' pour enregistrer un visage")
    print(" - 'r' pour recharger la base")
    print(" - 'Ã‰chap' pour quitter\n")

    threading.Thread(target=detection_thread_func, daemon=True).start()

    while True:
        ret, frame = cam.read()
        if not ret:
            print("âš ï¸ ProblÃ¨me de lecture de la camÃ©ra.")
            break

        with frame_lock:
            last_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).copy()
            display = annotated_frame.copy() if annotated_frame is not None else frame.copy()

        cv2.imshow("AI-SHA - SÃ©curitÃ© Visage & Mains", display)

        key = cv2.waitKey(1) & 0xFF
        if key == 27:
            break
        elif key == ord('s'):
            save_face()
            known_encodings[:], known_names[:] = load_known_faces()
        elif key == ord('r'):
            print("ðŸ” Rechargement de la base...")
            known_encodings[:], known_names[:] = load_known_faces()

    cam.release()
    cv2.destroyAllWindows()
    print("ðŸ‘‹ Fin du programme.")

if __name__ == "__main__":
    main()
